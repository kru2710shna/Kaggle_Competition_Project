{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "095abf8f",
   "metadata": {},
   "source": [
    "## Store Sales - Time Series Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3814202",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e328743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import plotly.express as px\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b813b3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "train_df= pd.read_csv(\"/Users/krushna/Downloads/store-sales-time-series-forecasting/train.csv\")\n",
    "test_df = pd.read_csv(\"/Users/krushna/Downloads/store-sales-time-series-forecasting/test.csv\")\n",
    "stores_df = pd.read_csv(\"/Users/krushna/Downloads/store-sales-time-series-forecasting/stores.csv\")\n",
    "transactions_df = pd.read_csv(\"/Users/krushna/Downloads/store-sales-time-series-forecasting/transactions.csv\")\n",
    "train_df=train_df.sort_values(['store_nbr', 'date'])\n",
    "transactions_df=transactions_df.sort_values(['store_nbr', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed70263",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['date'] = pd.to_datetime(train_df['date'])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7785ddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#formating\n",
    "train_df.onpromotion = train_df.onpromotion.astype(\"float16\")\n",
    "train_df.sales = train_df.sales.astype(\"float32\")\n",
    "stores_df.cluster = stores_df.cluster.astype(\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85afaa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df[\"date\"] = pd.to_datetime(transactions_df.date)\n",
    "transactions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f1bb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "temp = pd.merge(train_df.groupby(['date', 'store_nbr']).sales.sum().reset_index(), transactions_df, how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdef43b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Visualization\n",
    "print(\"Spearman Correlation Between Totals sales and Transactions: {:,.4f}\".format(temp.corr('spearman').sales.loc[\"transactions\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b45e484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Visualize \n",
    "px.line(transactions_df.sort_values([\"store_nbr\", \"date\"]), x='date', y='transactions', color='store_nbr',title = \"Transactions\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bf01fb",
   "metadata": {},
   "source": [
    "#### From this we can say that the transactions was maximum by the end of every year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0175a7",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6470df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check transactions for every month \n",
    "a = transactions_df.copy()\n",
    "a['date'] = pd.to_datetime(a['date'])\n",
    "a['year'] = a.date.dt.year\n",
    "a['month'] = a.date.dt.month\n",
    "px.box(a, x=\"year\", y=\"transactions\" , color = \"month\", title = \"Transactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866668bb",
   "metadata": {},
   "source": [
    "#### This confirms that the transactions is made he most in the month of december"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bef8625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check weekly \n",
    "b = transactions_df.copy()\n",
    "b['date'] = pd.to_datetime(a['date'])\n",
    "b['day'] = b.date.dt.day\n",
    "b['month'] = b.date.dt.month\n",
    "b['year'] = b.date.dt.year\n",
    "\n",
    "# Create a box plot for transactions with days on the x-axis\n",
    "px.box(b, x=\"day\", y=\"transactions\", color=\"month\", title=\"Transactions by Day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4da123",
   "metadata": {},
   "source": [
    "#### This shows that the transactions is more in last week of the month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788626b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(temp, x = \"transactions\", y = \"sales\", trendline = \"ols\", trendline_color_override = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e014933b",
   "metadata": {},
   "source": [
    "#### There is strong correlation between total sales and transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ce3d0d",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44963aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's use the next dataset and see how it is effective \n",
    "oil_df= pd.read_csv(\"/Users/krushna/Downloads/store-sales-time-series-forecasting/oil.csv\")\n",
    "# Converting datetime \n",
    "oil_df['date'] = pd.to_datetime(oil_df.date)\n",
    "# Resample\n",
    "oil_df = oil_df.set_index(\"date\").dcoilwtico.resample(\"D\").sum().reset_index()\n",
    "# Linear Interpolation \n",
    "oil_df[\"dcoilwtico\"] = np.where(oil_df[\"dcoilwtico\"] == 0, np.nan, oil_df[\"dcoilwtico\"])\n",
    "oil_df[\"dcoilwtico_interpolated\"] =oil_df.dcoilwtico.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b42994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Visualization\n",
    "p = oil_df.melt(id_vars=['date']+list(oil_df.keys()[5:]), var_name='Legend')\n",
    "px.line(p.sort_values([\"Legend\", \"date\"], ascending = [False, True]), x='date', y='value', color='Legend',title = \"Daily Oil Price\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f3950d",
   "metadata": {},
   "source": [
    "#### We see that the coreelation is appropate but the curve is negative.Now lets check the Correlation of oil price and transactions and oil price and sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c95110",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.merge(temp, oil_df, how = \"left\")\n",
    "print(\"Correlation with Daily Oil Prices\")\n",
    "print(temp.drop([\"store_nbr\", \"dcoilwtico\"], axis = 1).corr(\"spearman\").dcoilwtico_interpolated.loc[[\"sales\", \"transactions\"]], \"\\n\")\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize = (15,5))\n",
    "temp.plot.scatter(x = \"dcoilwtico_interpolated\", y = \"transactions\", ax=axes[0])\n",
    "temp.plot.scatter(x = \"dcoilwtico_interpolated\", y = \"sales\", ax=axes[1], color = \"r\")\n",
    "axes[0].set_title('Daily oil price & Transactions', fontsize = 15)\n",
    "axes[1].set_title('Daily Oil Price & Sales', fontsize = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac4be91",
   "metadata": {},
   "source": [
    "#### From this we can assume that the oil prices do make sense and we cannot ignore the dataset. As the oil prices increases the cost in Ecuador increases and economy goes down and due to that there are less sales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1443aefe",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f76b2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sales - Trget Variable \n",
    "\n",
    "# Looking for correlation matrix \n",
    "a = train_df[[\"store_nbr\", \"sales\"]]\n",
    "a[\"ind\"] = 1\n",
    "a[\"ind\"] = a.groupby(\"store_nbr\").ind.cumsum().values\n",
    "a = pd.pivot(a, index = \"ind\", columns = \"store_nbr\", values = \"sales\").corr()\n",
    "mask = np.triu(a.corr())\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(a,\n",
    "        annot=True,\n",
    "        fmt='.1f',\n",
    "        cmap='coolwarm',\n",
    "        square=True,\n",
    "        mask=mask,\n",
    "        linewidths=1,\n",
    "        cbar=False)\n",
    "plt.title(\"Correlations among stores\",fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887a2ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now lets consider the store number equivalent as well as the sales with dates\n",
    "a = train_df.set_index(\"date\").groupby(\"store_nbr\").resample(\"D\").sales.sum().reset_index()\n",
    "px.line(a, x = \"date\", y= \"sales\", color = \"store_nbr\", title = \"Daily total sales of the stores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ec9358",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is a 3-D Data so after clicking each store number \n",
    "## there we find a need to remove some str_nbr whcih had least \n",
    "## sales an can harm our model.\n",
    "print(train_df.shape)\n",
    "train_df = train_df[~((train_df.store_nbr == 52) & (train_df.date < \"2017-04-20\"))]\n",
    "train_df= train_df[~((train_df.store_nbr == 22) & (train_df.date < \"2015-10-09\"))]\n",
    "train_df= train_df[~((train_df.store_nbr == 42) & (train_df.date < \"2015-08-21\"))]\n",
    "train_df = train_df[~((train_df.store_nbr == 21) & (train_df.date < \"2015-07-24\"))]\n",
    "train_df= train_df[~((train_df.store_nbr == 29) & (train_df.date < \"2015-03-20\"))]\n",
    "train_df = train_df[~((train_df.store_nbr == 20) & (train_df.date < \"2015-02-13\"))]\n",
    "train_df = train_df[~((train_df.store_nbr == 53) & (train_df.date < \"2014-05-29\"))]\n",
    "train_df = train_df[~((train_df.store_nbr == 36) & (train_df.date < \"2013-05-09\"))]\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1ff7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = train_df.groupby([\"store_nbr\", \"family\"]).sales.sum().reset_index().sort_values([\"family\",\"store_nbr\"])\n",
    "c = c[c.sales == 0]\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed2e115",
   "metadata": {},
   "source": [
    "#### The table above shows the list of family and their sales with 0 valuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6fff56",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8de098f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.shape)\n",
    "# Anti Join\n",
    "outer_join = train_df.merge(c[c.sales == 0].drop(\"sales\",axis = 1), how = 'outer', indicator = True)\n",
    "train_df = outer_join[~(outer_join._merge == 'both')].drop('_merge', axis = 1)\n",
    "del outer_join\n",
    "gc.collect()\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e615d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Zero- Prediction\n",
    "zero_prediction = []\n",
    "for i in range(0,len(c)):\n",
    "    zero_prediction.append(\n",
    "        pd.DataFrame({\n",
    "            \"date\":pd.date_range(\"2017-08-16\", \"2017-08-31\").tolist(),\n",
    "            \"store_nbr\":c.store_nbr.iloc[i],\n",
    "            \"family\":c.family.iloc[i],\n",
    "            \"sales\":0\n",
    "        })\n",
    "    )\n",
    "zero_prediction = pd.concat(zero_prediction)\n",
    "del c\n",
    "gc.collect()\n",
    "zero_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b25b14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = train_df.groupby([\"family\", \"store_nbr\"]).tail(60).groupby([\"family\", \"store_nbr\"]).sales.sum().reset_index()\n",
    "c[c.sales == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b22ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Family like Babay Care, SCHOOL AND OFFICE SUPPLIES, Books\n",
    "#### Lawn and Gardens, Ladieswear, have no sales.\n",
    "#### Data Visualzization \n",
    "\n",
    "fig, ax = plt.subplots(1,5, figsize = (20,4))\n",
    "train_df[(train_df.store_nbr == 10) & (train_df.family == \"LAWN AND GARDEN\")].set_index(\"date\").sales.plot(ax = ax[0], title = \"STORE 10 - LAWN AND GARDEN\")\n",
    "train_df[(train_df.store_nbr == 36) & (train_df.family == \"LADIESWEAR\")].set_index(\"date\").sales.plot(ax = ax[1], title = \"STORE 36 - LADIESWEAR\")\n",
    "train_df[(train_df.store_nbr == 6) & (train_df.family == \"SCHOOL AND OFFICE SUPPLIES\")].set_index(\"date\").sales.plot(ax = ax[2], title = \"STORE 6 - SCHOOL AND OFFICE SUPPLIES\")\n",
    "train_df[(train_df.store_nbr == 14) & (train_df.family == \"BABY CARE\")].set_index(\"date\").sales.plot(ax = ax[3], title = \"STORE 14 - BABY CARE\")\n",
    "train_df[(train_df.store_nbr == 53) & (train_df.family == \"BOOKS\")].set_index(\"date\").sales.plot(ax = ax[4], title = \"STORE 43 - BOOKS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf514ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Check all families \n",
    "\n",
    "a = train_df.set_index(\"date\").groupby(\"family\").resample(\"D\").sales.sum().reset_index()\n",
    "px.line(a, x = \"date\", y= \"sales\", color = \"family\", title = \"Daily total sales of the family\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3f92a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train_df.groupby(\"family\").sales.mean().sort_values(ascending = False).reset_index()\n",
    "px.bar(a, y = \"family\", x=\"sales\", color = \"family\", title = \"Which product family preferred more?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478e7864",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's check How the sales changes over cities \n",
    "\n",
    "d = pd.merge(train_df, stores_df)\n",
    "d[\"store_nbr\"] = d[\"store_nbr\"].astype(\"int8\")\n",
    "d[\"year\"] = d.date.dt.year\n",
    "px.line(d.groupby([\"city\", \"year\"]).sales.mean().reset_index(), x = \"year\", y = \"sales\", color = \"city\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34c1d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets take a look for next Dataset - Holidays and Events\n",
    "\n",
    "holidays_df = pd.read_csv(\"/Users/krushna/Downloads/store-sales-time-series-forecasting/holidays_events.csv\")\n",
    "holidays_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c95cdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def create_date_features(df):\n",
    "    df['month'] = df.date.dt.month.astype(\"int8\")\n",
    "    df['day_of_month'] = df.date.dt.day.astype(\"int8\")\n",
    "    df['day_of_year'] = df.date.dt.dayofyear.astype(\"int16\")\n",
    "    df['week_of_month'] = (df.date.apply(lambda d: (d.day-1)//7+1)).astype(\"int8\")\n",
    "    \n",
    "    # Updated line for week_of_year\n",
    "    df['week_of_year'] = df.date.apply(lambda x: x.isocalendar()[1]).astype(\"int8\")\n",
    "\n",
    "    df['day_of_week'] = (df.date.dt.dayofweek + 1).astype(\"int8\")\n",
    "    df['year'] = df.date.dt.year.astype(\"int32\")\n",
    "    df[\"is_wknd\"] = (df.date.dt.weekday // 4).astype(\"int8\")\n",
    "    df[\"quarter\"] = df.date.dt.quarter.astype(\"int8\")\n",
    "    df['is_month_start'] = df.date.dt.is_month_start.astype(\"int8\")\n",
    "    df['is_month_end'] = df.date.dt.is_month_end.astype(\"int8\")\n",
    "    df['is_quarter_start'] = df.date.dt.is_quarter_start.astype(\"int8\")\n",
    "    df['is_quarter_end'] = df.date.dt.is_quarter_end.astype(\"int8\")\n",
    "    df['is_year_start'] = df.date.dt.is_year_start.astype(\"int8\")\n",
    "    df['is_year_end'] = df.date.dt.is_year_end.astype(\"int8\")\n",
    "    \n",
    "    # Season calculation\n",
    "    df[\"season\"] = np.where(df.month.isin([12, 1, 2]), 0, 1)\n",
    "    df[\"season\"] = np.where(df.month.isin([6, 7, 8]), 2, df[\"season\"])\n",
    "    df[\"season\"] = pd.Series(np.where(df.month.isin([9, 10, 11]), 3, df[\"season\"])).astype(\"int8\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Assuming 'date' is a datetime column in your DataFrame 'd'\n",
    "# Make sure 'date' is in the datetime format before applying the function\n",
    "d['date'] = pd.to_datetime(d['date'])\n",
    "d = create_date_features(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6e04e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lag Feature\n",
    "## ACF & PACF\n",
    "## PACF- Is very useful to decide which feature should we select \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4b611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = d[(d.sales.notnull())].groupby([\"date\", \"family\"]).sales.mean().reset_index().set_index(\"date\")\n",
    "for num, i in enumerate(a.family.unique()):\n",
    "    try:\n",
    "        fig, ax = plt.subplots(1,2,figsize=(15,5))\n",
    "        temp = a[(a.family == i)]#& (a.sales.notnull())\n",
    "        sm.graphics.tsa.plot_acf(temp.sales, lags=365, ax=ax[0], title = \"AUTOCORRELATION\\n\" + i)\n",
    "        sm.graphics.tsa.plot_pacf(temp.sales, lags=365, ax=ax[1], title = \"PARTIAL AUTOCORRELATION\\n\" + i)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b831764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = d[d.year.isin([2016,2017])].groupby([\"year\", \"day_of_year\"]).sales.mean().reset_index()\n",
    "px.line(a, x = \"day_of_year\", y = \"sales\", color = \"year\", title = \"Average sales for 2016 and 2017\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd17be1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple Moving  Average\n",
    "a = train_df.sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "for i in [20, 30, 45, 60, 90, 120, 365, 730]:\n",
    "    a[\"SMA\"+str(i)+\"_sales_lag16\"] = a.groupby([\"store_nbr\", \"family\"]).rolling(i).sales.mean().shift(16).values\n",
    "    a[\"SMA\"+str(i)+\"_sales_lag30\"] = a.groupby([\"store_nbr\", \"family\"]).rolling(i).sales.mean().shift(30).values\n",
    "    a[\"SMA\"+str(i)+\"_sales_lag60\"] = a.groupby([\"store_nbr\", \"family\"]).rolling(i).sales.mean().shift(60).values\n",
    "print(\"Correlation\")\n",
    "a[[\"sales\"]+a.columns[a.columns.str.startswith(\"SMA\")].tolist()].corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e42dc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a[(a.store_nbr == 1)].set_index(\"date\")\n",
    "for i in b.family.unique():\n",
    "    fig, ax = plt.subplots(2,4,figsize=(20,10))\n",
    "    b[b.family == i][[\"sales\", \"SMA20_sales_lag16\"]].plot(legend = True, ax = ax[0,0], linewidth = 4)\n",
    "    b[b.family == i][[\"sales\", \"SMA30_sales_lag16\"]].plot(legend = True, ax = ax[0,1], linewidth = 4)\n",
    "    b[b.family == i][[\"sales\", \"SMA45_sales_lag16\"]].plot(legend = True, ax = ax[0,2], linewidth = 4)\n",
    "    b[b.family == i][[\"sales\", \"SMA60_sales_lag16\"]].plot(legend = True, ax = ax[0,3], linewidth = 4)\n",
    "    b[b.family == i][[\"sales\", \"SMA90_sales_lag16\"]].plot(legend = True, ax = ax[1,0], linewidth = 4)\n",
    "    b[b.family == i][[\"sales\", \"SMA120_sales_lag16\"]].plot(legend = True, ax = ax[1,1], linewidth = 4)\n",
    "    b[b.family == i][[\"sales\", \"SMA365_sales_lag16\"]].plot(legend = True, ax = ax[1,2], linewidth = 4)\n",
    "    b[b.family == i][[\"sales\", \"SMA730_sales_lag16\"]].plot(legend = True, ax = ax[1,3], linewidth = 4)\n",
    "    plt.suptitle(\"STORE 1 - \"+i, fontsize = 15)\n",
    "    plt.tight_layout(pad = 1.5)\n",
    "    for j in range(0,4):\n",
    "        ax[0,j].legend(fontsize=\"x-large\")\n",
    "        ax[1,j].legend(fontsize=\"x-large\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b728d587",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fbb0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exponential Moving Average\n",
    "def ewm_features(dataframe, alphas, lags):\n",
    "    dataframe = dataframe.copy()\n",
    "    for alpha in alphas:\n",
    "        for lag in lags:\n",
    "            dataframe['sales_ewm_alpha_' + str(alpha).replace(\".\", \"\") + \"_lag_\" + str(lag)] = \\\n",
    "                dataframe.groupby([\"store_nbr\", \"family\"])['sales']. \\\n",
    "                    transform(lambda x: x.shift(lag).ewm(alpha=alpha).mean())\n",
    "    return dataframe\n",
    "\n",
    "alphas = [0.95, 0.9, 0.8, 0.7, 0.5]\n",
    "lags = [16, 30, 60, 90]\n",
    "\n",
    "a = ewm_features(a, alphas, lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4cd462",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[(a.store_nbr == 1) & (a.family == \"GROCERY I\")].set_index(\"date\")[[\"sales\", \"sales_ewm_alpha_095_lag_16\"]].plot(title = \"STORE 1 - GROCERY I\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0d0852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
